{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_classification_with_your_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6JApzL6g_jQ",
        "colab_type": "text"
      },
      "source": [
        "# image classification with your own data\n",
        "\n",
        "put images in the class directories for train, valid and test.\n",
        "\n",
        "for example, with 'HDH' and 'OH' classes \n",
        "* ./drive/My Drive/public/train/HDH/*.jpg\n",
        "* ./drive/My Drive/public/train/OH/*.jpg\n",
        "* ./drive/My Drive/public/valid/HDH/*.jpg\n",
        "* ./drive/My Drive/public/valid/OH/*.jpg\n",
        "* ./drive/My Drive/public/test/HDH/*.jpg\n",
        "* ./drive/My Drive/public/test/OH/*.jpg\n",
        "\n",
        "your model will be saved as 'teamX.model'\n",
        "\n",
        "have fun! \n",
        "(by hchoi@handong.edu, Nov. 30, 2019) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUQQHb4HKf8_",
        "colab_type": "code",
        "outputId": "23d08ad2-a5c3-4b2e-ce13-001cb49d9dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM4cBDItKoxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQt5CUzzh_z0",
        "colab_type": "text"
      },
      "source": [
        "# try different network architectures\n",
        "* different kernel size and numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtKn4Z--LLt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resize=(120, 120)\n",
        "input_size=(100, 100)\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(resize),\n",
        "        transforms.RandomCrop(input_size), # data augmentation\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.3, 0.3, 0.3])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(resize),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.3, 0.3, 0.3])\n",
        "    ]),\n",
        "}\n",
        "test_transform = data_transforms['valid']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4W51MsxM96w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyCNN(nn.Module):\n",
        "    def __init__(self, output_dim=10):\n",
        "        super(MyCNN,self).__init__()\n",
        "\n",
        "        self.output_dim=output_dim\n",
        "\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            nn.Conv2d(3,32,3,padding=1), # try with different kernels\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32,32,3,padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(4,4), # 32 x (25x25)\n",
        "            \n",
        "            nn.Conv2d(32,16,3,padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16,16,3,padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(5,5) # 16 x (5x5) \n",
        "        )\n",
        "        conv_size = self.get_conv_size(3, input_size)\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(conv_size,100),\n",
        "            nn.BatchNorm1d(100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,output_dim)\n",
        "        )       \n",
        "\n",
        "    def get_conv_size(self, channel, shape):\n",
        "        o = self.cnn_layers(torch.zeros(1, channel, *shape))\n",
        "        return int(np.prod(o.size()))\n",
        "        \n",
        "    def forward(self,x):\n",
        "        batch_size, c, h, w = x.data.size()\n",
        "        out = self.cnn_layers(x)\n",
        "        out = out.view(batch_size, -1)\n",
        "        out = self.fc_layer(out)\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtuFoEzamuB1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# try different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc2woMezKOVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.0005\n",
        "output_dim=5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = MyCNN(output_dim=output_dim).to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "param_list = list(model.children())\n",
        "print(param_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC_j9RVnnEyN",
        "colab_type": "text"
      },
      "source": [
        "**data loader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xuya0_VVQzZv",
        "colab_type": "code",
        "outputId": "c5919a32-3810-4368-822b-72cd7ef84536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "batch_size = 64 # try different batch_size values\n",
        "data_dir = './drive/My Drive/public/'\n",
        "train_dir = 'train'\n",
        "valid_dir = 'valid1'\n",
        "\n",
        "train_set = datasets.ImageFolder(data_dir+train_dir, data_transforms['train'])\n",
        "valid_set = datasets.ImageFolder(data_dir+valid_dir, data_transforms['valid'])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                              shuffle=True, num_workers=4)          \n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size,\n",
        "                                              shuffle=True, num_workers=4)\n",
        "\n",
        "train_size = len(train_set)\n",
        "valid_size = len(valid_set)\n",
        "\n",
        "class_names = train_set.classes\n",
        "\n",
        "print(class_names) \n",
        "print(f'Train image size: {train_size}')\n",
        "print(f'Validation image size: {valid_size}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ANH', 'HDH', 'Hyoam', 'NTH', 'OH']\n",
            "Train image size: 4186\n",
            "Validation image size: 241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBM8GgSNiZ6m",
        "colab_type": "text"
      },
      "source": [
        "**training**\n",
        "* implement 'early stopping' "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eDi5Aeba8Ha",
        "colab_type": "code",
        "outputId": "b45886a3-bd40-4019-9230-648d1a0980b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "result_dir = 'drive/My Drive/public/results/'\n",
        "num_epoch = 3 # try with different epochs and find the best epoch\n",
        "\n",
        "if not os.path.exists(result_dir):\n",
        "    os.mkdir(result_dir)    \n",
        "    \n",
        "for i in range(num_epoch):\n",
        "    model.train()\n",
        "    for j, [image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = loss_func(output,y_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        #if j % 30 == 0:\n",
        "        #   print(i,j, loss.data.cpu())\n",
        "    \n",
        "    model.eval()\n",
        "    hits = 0\n",
        "    for k,[image,label] in enumerate(valid_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "\n",
        "        output = model(x)\n",
        "        y_est = output.argmax(1)\n",
        "        hits = hits + sum(y_est == y_).cpu()\n",
        "    print('Epochs', i, 'Hits', int(hits), 'Accuracy', float(hits/(valid_size+0.0)))    \n",
        "\n",
        "torch.save(model, result_dir + 'teamX.model')\n",
        "print('training is done by max_epochs', num_epoch)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs 0 Hits 214 Accuracy 0.8879668116569519\n",
            "Epochs 1 Hits 217 Accuracy 0.9004149436950684\n",
            "Epochs 2 Hits 222 Accuracy 0.9211618304252625\n",
            "training is done by max_epochs 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZB-BIAhVc0w",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "training is done! \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klAJEc3Pg9-d",
        "colab_type": "text"
      },
      "source": [
        "**you can test your model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rCqCX6NjQZ1",
        "colab_type": "code",
        "outputId": "30ff6c82-5635-49ce-8193-1e915f808d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "test_batch_size = 10\n",
        "result_dir = 'drive/My Drive/public/results/'\n",
        "model_name = 'teamX.model'\n",
        "\n",
        "model = torch.load(result_dir + model_name)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "test_dir = './drive/My Drive/public/valid2'\n",
        "test_set = datasets.ImageFolder(test_dir, test_transform)\n",
        "              \n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size,\n",
        "                                          shuffle=False, num_workers=4)\n",
        "\n",
        "hits = 0\n",
        "for k,[image,label] in enumerate(test_loader):\n",
        "    x = image.to(device)\n",
        "    y_= label.to(device)\n",
        "  \n",
        "    output = model(x)\n",
        "    y_est = output.argmax(1)\n",
        "    print('Target', label.numpy(), 'Prediction', y_est.cpu().numpy())\n",
        "    hits = hits + sum(y_est == y_)\n",
        "print('hits', int(hits),'accuracy', float(hits/(len(test_set)+0.0)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target [0 0 0 0 0 0 0 0 0 0] Prediction [0 0 0 0 0 0 0 0 0 0]\n",
            "Target [0 0 0 0 0 0 0 0 0 0] Prediction [0 0 0 0 0 0 0 0 0 0]\n",
            "Target [0 0 0 0 0 0 0 0 0 0] Prediction [0 0 0 0 0 0 0 0 0 0]\n",
            "Target [0 0 0 0 0 0 0 0 0 0] Prediction [0 0 0 0 0 0 0 0 0 0]\n",
            "Target [1 1 1 1 1 1 1 1 1 1] Prediction [1 1 1 1 1 1 1 1 1 1]\n",
            "Target [1 1 1 1 1 1 1 1 1 1] Prediction [1 1 1 1 1 1 1 1 1 1]\n",
            "Target [1 1 1 1 1 1 1 1 1 1] Prediction [1 1 1 1 1 2 2 2 2 2]\n",
            "Target [1 1 1 1 1 1 1 1 1 1] Prediction [2 2 2 2 4 0 0 0 0 0]\n",
            "Target [2 2 2 2 2 2 2 2 2 2] Prediction [2 2 2 2 2 2 2 2 2 2]\n",
            "Target [2 2 2 2 2 2 2 2 2 2] Prediction [2 2 2 2 2 2 2 2 2 2]\n",
            "Target [2 2 2 2 2 2 2 2 2 2] Prediction [2 2 2 2 2 2 2 2 2 2]\n",
            "Target [2 2 2 2 2 2 2 2 2 2] Prediction [2 2 2 3 4 3 3 3 2 3]\n",
            "Target [3 3 3 3 3 3 3 3 3 3] Prediction [3 3 3 3 3 3 4 3 4 3]\n",
            "Target [3 3 3 3 3 3 3 3 3 3] Prediction [3 3 3 3 3 3 3 3 3 3]\n",
            "Target [3 3 3 3 3 3 3 3 3 3] Prediction [3 3 3 3 3 3 3 3 3 3]\n",
            "Target [3 3 3 3 3 3 3 3 3 3] Prediction [3 3 4 4 3 0 3 3 2 3]\n",
            "Target [4 4 4 4 4 4 4 4 4 4] Prediction [4 4 4 4 4 4 4 4 4 4]\n",
            "Target [4 4 4 4 4 4 4 4 4 4] Prediction [4 4 4 4 4 4 4 4 4 4]\n",
            "Target [4 4 4 4 4 4 4 4 4 4] Prediction [4 4 4 4 4 4 4 4 4 4]\n",
            "Target [4 4 4 4 4 4 4 4 4 4] Prediction [4 4 4 4 4 4 4 4 0 0]\n",
            "hits 171 accuracy 0.8549999594688416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN4IZGVQgzP0",
        "colab_type": "text"
      },
      "source": [
        "# classify one image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIROsL_pY__p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd0071fb-d60f-41c5-f457-cd85e0d94ebd"
      },
      "source": [
        "from skimage import io\n",
        "\n",
        "img_name = './drive/My Drive/public/data/test/test1.jpg'\n",
        "test_img = io.imread(img_name)\n",
        "test_img = transforms.ToPILImage()(test_img)\n",
        "test_img = test_transform(test_img)\n",
        "test_data = test_img.unsqueeze(0).to(device)\n",
        "\n",
        "output=model(test_data)\n",
        "\n",
        "class_id = output.argmax(dim=1).cpu().numpy()[0]\n",
        "print(img_name.split('/')[-1], '==>', class_id, class_names[class_id])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test1.jpg ==> 0 ANH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk9Nvlpxg6ew",
        "colab_type": "text"
      },
      "source": [
        "# classify all images in a directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsJeM_g0ZBNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "5578bebc-85f1-43c0-b9f4-8f91460b2f35"
      },
      "source": [
        "from skimage import io\n",
        "import glob\n",
        "\n",
        "img_dir = 'drive/My Drive/public/data/test/'\n",
        "file_list = glob.glob(img_dir + '*.*')\n",
        "for img_name in file_list:\n",
        "  test_img = io.imread(img_name)\n",
        "  test_img = transforms.ToPILImage()(test_img)\n",
        "  test_img = test_transform(test_img)\n",
        "  test_data = test_img.unsqueeze(0).to(device)\n",
        "\n",
        "  output=model(test_data)\n",
        "\n",
        "  class_id = output.argmax(dim=1).cpu().numpy()[0]\n",
        "  print(img_name.split('/')[-1], '==>', class_id, class_names[class_id])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D07_ANH22.jpg ==> 0 ANH\n",
            "D15_OH43.jpg ==> 3 NTH\n",
            "D06_HDH08.jpg ==> 1 HDH\n",
            "D08_Hyoam09.jpg ==> 2 Hyoam\n",
            "D12_NTH15.jpg ==> 3 NTH\n",
            "D04_OH18.jpeg ==> 4 OH\n",
            "D12_AHN36.jpg ==> 0 ANH\n",
            "D05_NTH31.jpg ==> 3 NTH\n",
            "D17_NTH08.jpg ==> 3 NTH\n",
            "D12_OH21.jpg ==> 4 OH\n",
            "D07_HDH45.jpg ==> 1 HDH\n",
            "D07_HDH30.jpg ==> 1 HDH\n",
            "D11_NTH15.jpeg ==> 3 NTH\n",
            "D01_Hyoam41.jpg ==> 2 Hyoam\n",
            "D06_ANH32.jpg ==> 0 ANH\n",
            "D09_NTH30.jpg ==> 3 NTH\n",
            "D13_ANH45.jpg ==> 0 ANH\n",
            "D13_ANH47.jpg ==> 0 ANH\n",
            "test1.jpg ==> 0 ANH\n",
            "D18_Hyoam40.JPG ==> 2 Hyoam\n",
            "D06_OH29.jpg ==> 4 OH\n",
            "D11_NTH01.jpeg ==> 3 NTH\n",
            "D05_NTH45.jpg ==> 3 NTH\n",
            "D15_OH31.jpg ==> 4 OH\n",
            "D15_HDH04.JPG ==> 1 HDH\n",
            "D08_ANH23.jpg ==> 0 ANH\n",
            "D18_NTH30.jpg ==> 3 NTH\n",
            "D09_Hyoam31.JPG ==> 2 Hyoam\n",
            "D03_OH13.jpg ==> 4 OH\n",
            "D07_HDH17.jpg ==> 0 ANH\n",
            "D09_Hyoam09.JPG ==> 2 Hyoam\n",
            "D10_ANH46.jpg ==> 0 ANH\n",
            "D13_NTH30.jpg ==> 3 NTH\n",
            "D14_OH12.jpg ==> 4 OH\n",
            "D07_HDH07.jpg ==> 0 ANH\n",
            "D09_HDH31.JPG ==> 1 HDH\n",
            "D08_OH29.jpg ==> 4 OH\n",
            "D18_ANH48.jpg ==> 0 ANH\n",
            "D01_OH22.jpg ==> 4 OH\n",
            "D05_NTH03.jpg ==> 3 NTH\n",
            "D07_HDH49.jpg ==> 1 HDH\n",
            "D02_HDH50.jpg ==> 1 HDH\n",
            "D18_Hyoam38.JPG ==> 2 Hyoam\n",
            "D11_Hyoam05.JPG ==> 2 Hyoam\n",
            "D06_OH41.jpg ==> 4 OH\n",
            "D13_ANH01.jpg ==> 0 ANH\n",
            "D17_Hyoam39.jpeg ==> 2 Hyoam\n",
            "D10_ANH09.jpg ==> 0 ANH\n",
            "D12_HDH10.jpg ==> 1 HDH\n",
            "D15_Hyoam47.jpg ==> 2 Hyoam\n",
            "D14_Hyoam12.jpg ==> 2 Hyoam\n",
            "D16_OH34.jpg ==> 4 OH\n",
            "D11_NTH30.jpeg ==> 3 NTH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6kZDqJpi74n",
        "colab_type": "text"
      },
      "source": [
        "The end! (hchoi@handong.edu)\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}